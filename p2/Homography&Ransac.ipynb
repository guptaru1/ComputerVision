{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d0d697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from skimage.transform import ProjectiveTransform, warp\n",
    "\n",
    "left_image = cv2.imread('bbb_left.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "right_image = cv2.imread('bbb_right.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "left_img = cv2.imread('bbb_left.jpg')\n",
    "left_rgb = cv2.cvtColor(left_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "right_img = cv2.imread('bbb_right.jpg')\n",
    "right_rgb = cv2.cvtColor(right_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(left_image, cmap='gray')\n",
    "plt.title('Left Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(right_image, cmap='gray')\n",
    "plt.title('Right Image')\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "# Create SIFT or SURF object (choose one)\n",
    "sift = cv2.SIFT_create()\n",
    "# surf = cv2.xfeatures2d.SURF_create()\n",
    "\n",
    "# Detect keypoints and compute descriptors\n",
    "keypoints_left, descriptors_left = sift.detectAndCompute(left_image, None)\n",
    "keypoints_right, descriptors_right = sift.detectAndCompute(right_image, None)\n",
    "\n",
    "# Draw keypoints on the images\n",
    "left_image_with_keypoints = cv2.drawKeypoints(left_image, keypoints_left, None)\n",
    "right_image_with_keypoints = cv2.drawKeypoints(right_image, keypoints_right, None)\n",
    "\n",
    "# Display images with keypoints\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(left_image_with_keypoints, cmap='gray')\n",
    "plt.title('Left Image with SIFT Keypoints')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(right_image_with_keypoints, cmap='gray')\n",
    "plt.title('Right Image with SIFT Keypoints')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "left_mean = np.mean(descriptors_left, axis=0)\n",
    "std_left = np.std(descriptors_left, axis=0)\n",
    "    \n",
    "des_left = (descriptors_left - left_mean) / std_left\n",
    "    \n",
    "right_mean = np.mean(descriptors_right, axis = 0)\n",
    "std_right = np.std(descriptors_right, axis = 0)\n",
    "    \n",
    "des_right = (descriptors_right - right_mean)/std_right\n",
    "    \n",
    "matching_scores = []\n",
    "    \n",
    "for i in range(len(descriptors_left)):\n",
    "        for j in range(len(descriptors_right)):\n",
    "            \n",
    "            euclidean_distance = np.linalg.norm(descriptors_left[i] - descriptors_right[j])\n",
    "            matching_scores.append(euclidean_distance)\n",
    "    \n",
    "matching_scores = np.array(matching_scores)\n",
    "\n",
    "matching_scores_new = np.linalg.norm(descriptors_left[:, np.newaxis, :] - descriptors_right, axis=2)\n",
    "print(\"Matching_Scores\", matching_scores_new)\n",
    "\n",
    "\n",
    "def get_pair_min_distances(num_pairs, matching_scores,kp1,kp2):\n",
    "    dist_image_1 = []\n",
    "    dist_image_2 = []\n",
    "    min_distance = []\n",
    "    \n",
    "    print(\"Matching scores shape\", matching_scores.shape)\n",
    "    \n",
    "    for desc_1 in range(matching_scores.shape[0]):\n",
    "        dist_image_1.append(min(matching_scores[desc_1,:]))\n",
    "    for desc_2 in range(matching_scores.shape[1]):\n",
    "        dist_image_2.append(min(matching_scores[:,desc_2]))\n",
    "    \n",
    "    for i in range(len(dist_image_1)):\n",
    "        for j in range(len(dist_image_2)):\n",
    "            if dist_image_1[i] == dist_image_2[j]:\n",
    "                min_distance.append([dist_image_1[i],i,j])\n",
    "    min_distance = sorted(min_distance)[:num_pairs]\n",
    "    data = []\n",
    "    for item in min_distance:\n",
    "        x1, y1 = kp1[item[1]].pt\n",
    "        x2, y2 = kp2[item[2]].pt\n",
    "        data.append([x1, y1, x2, y2])\n",
    "    data = np.array(data, dtype = 'int')\n",
    "    return data\n",
    "            \n",
    "        \n",
    "pairwise_distances = get_pair_min_distances(500, matching_scores_new,keypoints_left,keypoints_right)\n",
    "    \n",
    "def homography(four_matches):\n",
    "    #direct linear transform and singular value decomposition\n",
    "    A = []\n",
    "    for match in four_matches:\n",
    "        x_1, y_1 = match[0], match[1] # x, y\n",
    "        x_2, y_2 = match[2], match[3]\n",
    "        A.append([x_1, y_1, 1, 0, 0, 0, -x_1*x_2, -y_1*x_2, -x_2])\n",
    "        A.append([0, 0, 0, x_1, y_1, 1, -x_1*y_2, -y_1*y_2, -y_2])\n",
    "        \n",
    "    U, S, V = np.linalg.svd(np.matrix(A))\n",
    "    h = np.reshape(V[8], (3, 3))\n",
    "    h = (1/h.item(8)) * h\n",
    "    return h\n",
    "\n",
    "def residual(match, H):\n",
    "    p1 = np.transpose(np.matrix([match[0], match[1], 1]))\n",
    "    estimatep2 = np.dot(H, p1)\n",
    "    #normalise all points of estimatedp2 to ensure the homogenous corordiante is set to 1\n",
    "    estimatep2 = (1/estimatep2.item(2))*estimatep2\n",
    "    \n",
    "    p2 = np.transpose(np.matrix([match[2], match[3], 1]))\n",
    "    error = p2 - estimatep2\n",
    "    return np.linalg.norm(error)\n",
    "\n",
    "def RANSAC(data, iteration = 1500,threshold=0.6):\n",
    "    best_model, best_residual, num_best_inliers = None, None, []\n",
    "    for i in range(iteration):\n",
    "        match1 = data[random.randrange(0, len(data))]\n",
    "        match2 = data[random.randrange(0, len(data))]\n",
    "        fourMatches = np.vstack((match1, match2))\n",
    "        match3 = data[random.randrange(0, len(data))]\n",
    "        fourMatches = np.vstack((fourMatches, match3))\n",
    "        match4 = data[random.randrange(0, len(data))]\n",
    "        #four matches as homography has 8 variables so need min 4 points\n",
    "        fourMatches = np.vstack((fourMatches, match4))\n",
    "        \n",
    "        H = homography(fourMatches)\n",
    "        \n",
    "        #  avoid dividing by zero \n",
    "        #if np.linalg.matrix_rank(H) < 3:\n",
    "            #print(\"Coming in here\")\n",
    "            #continue\n",
    "            \n",
    "        #good matching points\n",
    "        inliers = []\n",
    "        all_residual = 0\n",
    "        #go throught all the match points using the matrix h obtained\n",
    "        for i in range(len(data)):\n",
    "            \n",
    "            r = residual(data[i], H)\n",
    "            if r < 6:\n",
    "                \n",
    "                inliers.append(data[i])\n",
    "            all_residual += r\n",
    "\n",
    "        #check if this was the ebst model found yet\n",
    "        if len(inliers) > len(num_best_inliers):\n",
    "            num_best_inliers = inliers\n",
    "            best_model = H\n",
    "            best_residual = all_residual / len(data)\n",
    "            print(\"best model \", best_model,\"Best residual\", best_residual, \"Max inliers: \", len(num_best_inliers))\n",
    "        #Threshold condition\n",
    "        if len(num_best_inliers) > (len(data)*threshold):\n",
    "            break\n",
    "            \n",
    "    return best_model,num_best_inliers, best_residual\n",
    "        \n",
    "        #construct a sampel of s from teh data points\n",
    "        \n",
    "# Initialize the feature matcher using brute-force matching\n",
    "#bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "\n",
    "# Match the descriptors using brute-force matching\n",
    "#matches_bf = bf.match(descriptors1, descriptors2)\n",
    "\n",
    "def warp_images(H, img1, img2):\n",
    "    \"\"\"\n",
    "    stitch images together according to the homography\n",
    "    \"\"\"\n",
    "   \n",
    "    height = img1.shape[0]\n",
    "    width = img1.shape[1] + img2.shape[1]\n",
    "    depth = img1.shape[2]\n",
    "    trans = ProjectiveTransform(H)\n",
    "    #apply homography to the image 2\n",
    "    img2_trans = warp(img2, trans, output_shape=(height,width,depth))\n",
    "    #convert pixel into the range of 0 to 255\n",
    "    img2_trans = img2_trans * 255.\n",
    "    img2_trans = img2_trans.astype('int')\n",
    "    \n",
    "    #create a sample image\n",
    "    img1_trans = np.zeros((height, width, depth), dtype = 'int')\n",
    "    #make the columns upto a certain point of image1, the left part is all image 1\n",
    "    \n",
    "    img1_trans[:,:img1.shape[1]] = img1\n",
    "    \n",
    "    #final image to return\n",
    "    warped_img = np.zeros((height, width, depth), dtype = 'int')\n",
    "    #rows\n",
    "    for i in range(warped_img.shape[0]):\n",
    "        #cols\n",
    "        for j in range(warped_img.shape[1]):\n",
    "           # if (img2_trans[i][j] != 0).all() and (img1_trans[i][j] != 0).all():\n",
    "                #warped_img[i][j] = (img2_trans[i][j] + img1_trans[i][j]) / 2\n",
    "            if (img2_trans[i][j] != 0).all():\n",
    "                warped_img[i][j] = img2_trans[i][j]\n",
    "            else:\n",
    "                warped_img[i][j] = img1_trans[i][j]\n",
    "#     plt.figure()\n",
    "#     plt.imshow(warped_img)\n",
    "#     plt.show()\n",
    "    return warped_img\n",
    "\n",
    "def w_images( H,left,right):\n",
    "\n",
    "    \n",
    "    # Convert to double and normalize. Avoid noise.\n",
    "    left = cv2.normalize(left.astype('float'), None, \n",
    "                            0.0, 1.0, cv2.NORM_MINMAX)   \n",
    "    # Convert to double and normalize.\n",
    "    right = cv2.normalize(right.astype('float'), None, \n",
    "                            0.0, 1.0, cv2.NORM_MINMAX)\n",
    "    \n",
    "    height_l, width_l, channel_l = left.shape\n",
    "    #corners of current left image\n",
    "    corners = [[0, 0, 1], [width_l, 0, 1], [width_l, height_l, 1], [0, height_l, 1]]\n",
    "    new_corners = [np.dot(H, corner) for corner in corners]\n",
    "    corners_new = np.array(new_corners).T \n",
    "    \n",
    "    #represent correct pixel positions in the cartesian co-ordianate for pixels\n",
    "    cartesian_x = corners_new[0]/corners_new[2]\n",
    "    cartesian_y = corners_new[1] / corners_new[2]\n",
    "    \n",
    "    y_min = min(cartesian_y)\n",
    "    x_min = min(cartesian_x)\n",
    "    \n",
    "    translation_mat = np.array([[1, 0, -x_min], [0, 1, -y_min], [0, 0, 1]])\n",
    "    H = np.dot(translation_mat, H)\n",
    "    height_new = int(round(abs(y_min) + height_l))\n",
    "    width_new = int(round(abs(x_min) + width_l))\n",
    "    size = (width_new, height_new)\n",
    "    \n",
    "    warped_l = cv2.warpPerspective(src=left, M=H, dsize=size)\n",
    "    \n",
    "    height_r, width_r, channel_r = right.shape\n",
    "    \n",
    "    height_new = int(round(abs(y_min) + height_r))\n",
    "    width_new = int(round(abs(x_min) + width_r))\n",
    "    size = (width_new, height_new)\n",
    "    warped_r = cv2.warpPerspective(src=right, M=translation_mat, dsize=size)\n",
    "    \n",
    "        # Stitching procedure, store results in warped_l.\n",
    "    for i in tqdm(range(warped_r.shape[0])):\n",
    "        for j in range(warped_r.shape[1]):\n",
    "            pixel_l = warped_l[i, j, :]\n",
    "            pixel_r = warped_r[i, j, :]\n",
    "            \n",
    "            if not np.array_equal(pixel_l, black) and np.array_equal(pixel_r, black):\n",
    "                warped_l[i, j, :] = pixel_l\n",
    "            elif np.array_equal(pixel_l, black) and not np.array_equal(pixel_r, black):\n",
    "                warped_l[i, j, :] = pixel_r\n",
    "            elif not np.array_equal(pixel_l, black) and not np.array_equal(pixel_r, black):\n",
    "                warped_l[i, j, :] = (pixel_l + pixel_r) / 2\n",
    "            else:\n",
    "                pass\n",
    "                  \n",
    "    stitch_image = warped_l[:warped_r.shape[0], :warped_r.shape[1], :]\n",
    "    return stitch_image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Check if this script is the main script being run\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Hello world\")\n",
    "    #call the function\n",
    "    data = get_pair_min_distances(250, matching_scores_new,keypoints_left,keypoints_right)\n",
    "    H, max_inliers, best_model_errors = RANSAC(data)\n",
    "    matches = max_inliers\n",
    "    # Convert keypoint objects to numpy arrays\n",
    "    #keypoints1 = np.float32([keypoints_left[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    #keypoints2 = np.float32([keypoints_right[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "    # Create an output image that combines the two input images side by side\n",
    "    #img_matches = np.hstack((img1, img2))\n",
    "\n",
    "    # Draw the matches\n",
    "    #img_matches = cv2.drawMatches(img1, keypoints1, img2, keypoints2, matches, img_matches)\n",
    "    # Convert the BGR image to RGB\n",
    "    #img_matches_rgb = cv2.cvtColor(img_matches, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display the matches using plt.imshow\n",
    "    #print(\"Best model:\", best_model)\n",
    "    #print(\"Average residual:\", np.average(best_model_errors))\n",
    "    #print(\"Inliers:\", len(max_inliers))\n",
    "    \n",
    "    #matched_image = cv2.drawMatches(left_image, keypoints_left, right_image, keypoints_right, max_inliers, None)\n",
    "    #matched_image_rgb = cv2.cvtColor(matched_image, cv2.COLOR_BGR2RGB)\n",
    "    #plt.imshow(warp_images(H, left_rgb, right_rgb,))\n",
    "    plt.imshow(warp_images(H, left_rgb, right_rgb,))\n",
    "    \n",
    "    #plt.imshow(matched_image_rgb)  # Display the image\n",
    "    plt.axis('off')  # Turn off axis labels and ticks (optional)\n",
    "    plt.show()  # Show the image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175d1a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9e69c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c181d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
